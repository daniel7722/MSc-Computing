{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76ea2fe-fb4b-4d66-8f4c-ecb39d1c36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c7c97-d8c3-41e4-aa58-fba864282d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b78b3be-fd24-492b-a3c4-6f3b92433eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filepath):\n",
    "    \"\"\" Read in the dataset from the specified filepath\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The filepath to the dataset file\n",
    "\n",
    "    Returns:\n",
    "        tuple: returns a tuple of (x, y, classes), each being a numpy array. \n",
    "               - x is a numpy array with shape (N, K), \n",
    "                   where N is the number of instances\n",
    "                   K is the number of features/attributes\n",
    "               - y is a numpy array with shape (N, ), and each element should be \n",
    "                   an integer from 0 to C-1 where C is the number of classes \n",
    "               - classes : a numpy array with shape (C, ), which contains the \n",
    "                   unique class labels corresponding to the integers in y\n",
    "    \"\"\"\n",
    "\n",
    "    x = []\n",
    "    y_labels = []\n",
    "    for line in open(filepath):\n",
    "        if line.strip() != \"\": # handle empty rows in file\n",
    "            row = line.strip().split(\",\")\n",
    "            x.append(list(map(float, row[:-1]))) \n",
    "            y_labels.append(row[-1])\n",
    "    \n",
    "\n",
    "    x = np.array(x, dtype=int)\n",
    "    y = np.array(y_labels)\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44f43d80-04c0-4a90-b8a1-57cfafdfdaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "def split_dataset(x, y, test_proportion, random_generator=default_rng()):\n",
    "    \"\"\" Split dataset into training and test sets, according to the given\n",
    "        test set proportion.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Instances, numpy array with shape (N,K)\n",
    "        y (np.ndarray): Class labels, numpy array with shape (N,)\n",
    "        test_proportion (float): the desired proportion of test examples\n",
    "                                 (0.0-1.0)\n",
    "        random_generator (np.random.Generator): A random generator\n",
    "\n",
    "    Returns:\n",
    "        tuple: returns a tuple of (x_train, x_test, y_train, y_test)\n",
    "               - x_train (np.ndarray): Training instances shape (N_train, K)\n",
    "               - x_test (np.ndarray): Test instances shape (N_test, K)\n",
    "               - y_train (np.ndarray): Training labels, shape (N_train, )\n",
    "               - y_test (np.ndarray): Test labels, shape (N_train, )\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Complete this function\n",
    "    indices = np.arange(len(x))\n",
    "    random_generator.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    x_row, x_col = x.shape\n",
    "    partition = 1- int(x_row * test_proportion)\n",
    "    x_train = x[:partition, :]\n",
    "    x_test = x[partition:, :]\n",
    "    y_train = y[:partition]\n",
    "    y_test = y[partition:]\n",
    "    print(x_test.shape)\n",
    "\n",
    "    return (x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06d3a3b-a300-428d-8a4e-a759148491a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q' 'C' 'Q' 'Q' 'G' 'C' 'E' 'C' 'O' 'E' 'A' 'A' 'G' 'A' 'A' 'A' 'G' 'G'\n",
      " 'E' 'E' 'E' 'E' 'O' 'C' 'Q' 'Q' 'Q' 'C' 'O' 'Q' 'G' 'Q' 'G' 'O' 'Q' 'Q'\n",
      " 'G' 'O' 'Q' 'A' 'C' 'Q' 'O' 'Q' 'A' 'G' 'O' 'E' 'E' 'A' 'Q' 'G' 'A' 'C'\n",
      " 'A' 'G' 'A' 'C' 'O' 'C' 'O' 'E' 'G' 'Q' 'O' 'E' 'C' 'A' 'A' 'G' 'A' 'C'\n",
      " 'C' 'Q' 'O' 'O' 'O' 'A' 'E' 'C' 'A' 'Q' 'O' 'Q' 'C' 'A' 'A' 'Q' 'C' 'E'\n",
      " 'A' 'A' 'C' 'Q' 'A' 'Q' 'O' 'Q' 'O' 'G' 'C' 'G' 'C' 'C' 'O' 'Q' 'A' 'Q'\n",
      " 'Q' 'C' 'G' 'Q' 'C' 'Q' 'O' 'Q' 'O' 'G' 'Q' 'E' 'O' 'Q' 'E' 'Q' 'O' 'E'\n",
      " 'O' 'C' 'O' 'A' 'G' 'Q' 'E' 'G' 'O' 'Q' 'E' 'O' 'C' 'O' 'G' 'G' 'Q' 'Q'\n",
      " 'E' 'E' 'A' 'C' 'A' 'A' 'A' 'A' 'C' 'O' 'Q' 'G' 'O' 'O' 'E' 'C' 'C' 'Q'\n",
      " 'Q' 'C' 'C' 'O' 'C' 'A' 'G' 'A' 'C' 'A' 'C' 'G' 'E' 'Q' 'E' 'C' 'O' 'A'\n",
      " 'C' 'E' 'C' 'G' 'G' 'Q' 'G' 'Q' 'A' 'C' 'C' 'E' 'G' 'E' 'A' 'E' 'Q' 'O'\n",
      " 'O' 'O']\n"
     ]
    }
   ],
   "source": [
    "(x_test, y_test) = read_dataset(\"data/test.txt\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38834672-4aab-46f8-91a6-600c9623899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_val, y_val) = read_dataset(\"data/validation.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d108024f-c9d6-4c09-82b8-1f73ad2b2333",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_full, y_full) = read_dataset(\"data/train_full.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddb3d165-4f38-4e9d-9c53-51dd8b00f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_toy, y_toy) = read_dataset(\"data/toy.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dc8c7b5-095e-4f6d-8041-e6575365346c",
   "metadata": {},
   "outputs": [],
   "source": [
    " def confusion_matrix(y_gold, y_prediction, class_labels=None):\n",
    "    \n",
    "    # if no class_labels are given, we obtain the set of unique class labels from\n",
    "    # the union of the ground truth annotation and the prediction\n",
    "    if not class_labels:\n",
    "        class_labels = np.unique(np.concatenate((y_gold, y_prediction)))\n",
    "\n",
    "    confusion = np.zeros((len(class_labels), len(class_labels)), dtype=np.int64)\n",
    "\n",
    "    # for each correct class (row), \n",
    "    # compute how many instances are predicted for each class (columns)\n",
    "    for (i, label) in enumerate(class_labels):\n",
    "        # get predictions where the ground truth is the current class label\n",
    "        indices = (y_gold == label)\n",
    "        gold = y_gold[indices]\n",
    "        predictions = y_prediction[indices]\n",
    "\n",
    "        # quick way to get the counts per label\n",
    "        (unique_labels, counts) = np.unique(predictions, return_counts=True)\n",
    "\n",
    "        # convert the counts to a dictionary\n",
    "        frequency_dict = dict(zip(unique_labels, counts))\n",
    "\n",
    "        # fill up the confusion matrix for the current row\n",
    "        for (j, class_label) in enumerate(class_labels):\n",
    "            confusion[i, j] = frequency_dict.get(class_label, 0)\n",
    "\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c9c4057-5a53-49cf-8040-76e43c4e8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    " def recall(y_gold, y_prediction):\n",
    "\n",
    "    confusion = confusion_matrix(y_gold, y_prediction)\n",
    "    r = np.zeros((len(confusion), ))\n",
    "    for c in range(confusion.shape[0]):\n",
    "        if np.sum(confusion[c, :]) > 0:\n",
    "            r[c] = confusion[c, c] / np.sum(confusion[c, :])\n",
    "\n",
    "    macro_r = 0.\n",
    "    if len(r) > 0:\n",
    "        macro_r = np.mean(r)\n",
    "    return (r, macro_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c48aef1-2386-4029-98e5-8ca8e898d3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_gold, y_prediction):\n",
    "\n",
    "    confusion = confusion_matrix(y_gold, y_prediction)\n",
    "    p = np.zeros((len(confusion), ))\n",
    "    for c in range(confusion.shape[0]):\n",
    "        if np.sum(confusion[:, c]) > 0:\n",
    "            p[c] = confusion[c, c] / np.sum(confusion[:, c])\n",
    "\n",
    "    macro_p = 0.\n",
    "    if len(p) > 0:\n",
    "        macro_p = np.mean(p)\n",
    "    \n",
    "    return (p, macro_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d5a8f6c-4cf9-4f73-bf82-4ef8f27c2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_gold, y_prediction):\n",
    "\n",
    "    (precisions, macro_p) = precision(y_gold, y_prediction)\n",
    "    (recalls, macro_r) = recall(y_gold, y_prediction)\n",
    "\n",
    "    # just to make sure they are of the same length\n",
    "    assert len(precisions) == len(recalls)\n",
    "\n",
    "    f = np.zeros((len(precisions), ))\n",
    "    for c, (p, r) in enumerate(zip(precisions, recalls)):\n",
    "        if p + r > 0:\n",
    "            f[c] = 2 * p * r / (p + r)\n",
    "\n",
    "    macro_f = 0.\n",
    "    if len(f) > 0:\n",
    "        macro_f = np.mean(f)\n",
    "    \n",
    "    return (f, macro_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31ab90fb-c774-45ba-8680-3afe901c48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x, y):\n",
    "    return np.sum(x==y)*100/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "13fba0d8-381c-4fa0-9071-afc993cd27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, split_val=None, column=None, label=None):\n",
    "        self.left = self.right = None\n",
    "        self.split_val = split_val\n",
    "        self.column = column\n",
    "        self.label = label\n",
    "        \n",
    "    def add_child(self, child): \n",
    "        if self.left == None:\n",
    "            self.left = child\n",
    "        elif self.right == None:\n",
    "            self.right = child\n",
    "        else:\n",
    "            print(\"no children node free\")\n",
    "            exit()\n",
    "\n",
    "    def is_leaf(self):\n",
    "        if self.label != None:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def max_depth(self, d=0):\n",
    "\n",
    "        if self.left == None and self.right == None:\n",
    "            return 0\n",
    "        \n",
    "        left_depth = self.left.max_depth(d) + 1\n",
    "        right_depth = self.right.max_depth(d) + 1\n",
    "\n",
    "        if right_depth >= left_depth:\n",
    "            return right_depth\n",
    "        else:\n",
    "            return left_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fdbb9704-30d9-48d9-b86b-65ae716cba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(object):\n",
    "    \"\"\" Basic decision tree classifier\n",
    "    \n",
    "    Attributes:\n",
    "    is_trained (bool): Keeps track of whether the classifier has been trained\n",
    "    \n",
    "    Methods:\n",
    "    fit(x, y): Constructs a decision tree from data X and label y\n",
    "    predict(x): Predicts the class label of samples X\n",
    "    prune(x_val, y_val): Post-prunes the decision tree\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_layers_to_prune=None, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.is_trained = False\n",
    "        self.root = None\n",
    "        self.num_layers_to_prune = num_layers_to_prune\n",
    "        self.max_depth = 0\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "\n",
    "    \n",
    "    def calculate_entropy(self, y):\n",
    "        values, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / counts.sum()\n",
    "        entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "        return entropy\n",
    "\n",
    "    \n",
    "    def calculate_info_gain(self, x, y, x_val, sort_col):\n",
    "\n",
    "        # Calculate total entropy for overall data\n",
    "        total_entropy = self.calculate_entropy(y)\n",
    "\n",
    "        # Calculate entropy for left and right of split\n",
    "        left_entropy = self.calculate_entropy(y[x[:, sort_col] < x_val])\n",
    "        right_entropy = self.calculate_entropy(y[x[:, sort_col] >= x_val])\n",
    "\n",
    "        # Calculate info gain\n",
    "        info_gain = total_entropy - ((len(y[x[:, sort_col] < x_val])/len(y) * left_entropy) \n",
    "                                    + (len(y[x[:, sort_col] >= x_val])/len(y) * right_entropy))\n",
    "        \n",
    "        return info_gain\n",
    "\n",
    "        \n",
    "    def find_best_node(self, x, y):\n",
    "        y = y.reshape(-1, 1)\n",
    "\n",
    "        # To keep track of info gain\n",
    "        max_gain = value_to_split_on = column_to_split_on = None\n",
    "                \n",
    "        # loop through each column \n",
    "        for i in range(x.shape[1]):\n",
    "            # sort by that column\n",
    "            index_list = x[:, i].argsort()\n",
    "            x = x[index_list]\n",
    "            y = y[index_list]\n",
    "\n",
    "            starting_label = y[0]\n",
    "            starting_val = x[:, i][0]\n",
    "\n",
    "            # loop through the column\n",
    "            for x_val, y_val in zip(x[:, i], y):\n",
    "                if (y_val != starting_label) and (x_val != starting_val):\n",
    "\n",
    "                    # calculate information gain\n",
    "                    info_gain = self.calculate_info_gain(x, y, x_val, i)\n",
    "                    \n",
    "                    # update the max information gain\n",
    "                    if max_gain is None or info_gain > max_gain:\n",
    "                        max_gain = info_gain\n",
    "                        value_to_split_on = x_val\n",
    "                        column_to_split_on = i\n",
    "\n",
    "                    # Update starting label\n",
    "                    starting_label = y_val\n",
    "                    starting_val = x_val\n",
    "                    \n",
    "        return Node(value_to_split_on, column_to_split_on)\n",
    "\n",
    "\n",
    "    def split_dataset(self, x, y, node):\n",
    "        # Simplified dataset splitting\n",
    "        left_mask = x[:, node.column] < node.split_val\n",
    "        right_mask = ~left_mask  # Inverse of left_mask\n",
    "        return (x[left_mask], y[left_mask]), (x[right_mask], y[right_mask])\n",
    "\n",
    "\n",
    "    \n",
    "    def induce_decision_tree(self, x, y, depth=0):\n",
    "        if len(np.unique(y)) <= 1 or x.shape[0] < self.min_samples_split or depth == self.max_depth:\n",
    "            label_set, count = np.unique(y, return_counts=True)\n",
    "            leaf_node = Node(label=label_set[np.argmax(count)])\n",
    "            return leaf_node\n",
    "        else:\n",
    "            parent = self.find_best_node(x, y)\n",
    "            if parent.split_val is None or x.shape[0] <= self.min_samples_leaf:\n",
    "                label_set, count = np.unique(y, return_counts=True)\n",
    "                leaf_node = Node(label=label_set[np.argmax(count)])\n",
    "                return leaf_node\n",
    "            \n",
    "            (x_left, y_left), (x_right, y_right) = self.split_dataset(x, y, parent)\n",
    "            \n",
    "            if len(y_left) >= self.min_samples_leaf and len(y_right) >= self.min_samples_leaf:\n",
    "                parent.left = self.induce_decision_tree(x_left, y_left, depth + 1)\n",
    "                parent.right = self.induce_decision_tree(x_right, y_right, depth + 1)\n",
    "            else:\n",
    "                label_set, count = np.unique(y, return_counts=True)\n",
    "                return Node(label=label_set[np.argmax(count)])\n",
    "            \n",
    "            return parent\n",
    "\n",
    "\n",
    "    def fit(self, x, y):\n",
    "\n",
    "        \n",
    "        # Make sure that x and y have the same number of instances\n",
    "        assert x.shape[0] == len(y), \\\n",
    "            \"Training failed. x and y must have the same number of instances.\"\n",
    "        \n",
    "        #######################################################################\n",
    "        #                 ** TASK 2.1: COMPLETE THIS METHOD **\n",
    "        #######################################################################\n",
    "        self.max_depth = np.inf\n",
    "        self.root = self.induce_decision_tree(x, y)\n",
    "        self.max_depth = self.get_max_depth_from_tree() - self.num_layers_to_prune\n",
    "\n",
    "        self.root = self.induce_decision_tree(x, y)\n",
    "        \n",
    "        # set a flag so that we know that the classifier has been trained\n",
    "        self.is_trained = True\n",
    "\n",
    "    \n",
    "    def classify_instance(self, instance, node):\n",
    "\n",
    "        if node.label != None:\n",
    "            return node.label\n",
    "\n",
    "        if instance[node.column] >= node.split_val:\n",
    "            return self.classify_instance(instance, node.right)\n",
    "        \n",
    "        return self.classify_instance(instance, node.left)\n",
    "        \n",
    "    \n",
    "    def predict(self, x):\n",
    "\n",
    "        \n",
    "        # make sure that the classifier has been trained before predicting\n",
    "        if not self.is_trained:\n",
    "            raise Exception(\"DecisionTreeClassifier has not yet been trained.\")\n",
    "        \n",
    "        # set up an empty (M, ) numpy array to store the predicted labels \n",
    "        # feel free to change this if needed\n",
    "        predictions = np.zeros((x.shape[0],), dtype=object)\n",
    "        #######################################################################\n",
    "        #                 ** TASK 2.2: COMPLETE THIS METHOD **\n",
    "        #######################################################################\n",
    "        for i in range(len(x)):\n",
    "            label = self.classify_instance(x[i], self.root)\n",
    "            predictions[i] = label\n",
    "    \n",
    "        return predictions\n",
    "\n",
    "    def get_max_depth_from_tree(self):\n",
    "        return self.root.max_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2e9d50f8-3158-4a06-952b-fab42252f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = DecisionTreeClassifier(8);\n",
    "t.fit(x_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aa453db1-5afc-4c8e-a509-3f43a6ab36f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "93.0\n"
     ]
    }
   ],
   "source": [
    "print(t.get_max_depth_from_tree())\n",
    "\n",
    "predict = t.predict(x_val)\n",
    "\n",
    "print(accuracy(predict, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4ec3206d-5a2b-4820-a5d4-25feea10d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier(object):\n",
    "\n",
    "    def __init__(self, treesNum, num_layers_to_prune=0, min_samples_split=2, min_samples_leaf=1, feature_proportion=1):\n",
    "        self.is_trained = False\n",
    "        self.roots = []\n",
    "        self.treesNum = treesNum\n",
    "        self.prune_layer_num = num_layers_to_prune\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.feature_proportion = feature_proportion\n",
    "\n",
    "    def fit(self, x, y):\n",
    "\n",
    "        features_num = int(x.shape[1] * self.feature_proportion)\n",
    "        \n",
    "        # for treesNum\n",
    "        for i in range(self.treesNum):\n",
    "            # bagged samples from x\n",
    "            bagged_ints = np.random.randint(0, len(x), len(x), dtype=int)\n",
    "            x_bagged = x[bagged_ints, :]\n",
    "            y_bagged = y[bagged_ints]\n",
    "\n",
    "            features = np.arange(0,x.shape[1])\n",
    "            np.random.shuffle(features)\n",
    "            feature_list = features[:features_num]\n",
    "            x_bagged = x_bagged[:, feature_list]\n",
    "            \n",
    "            # train a tree on this subset\n",
    "            tree = DecisionTreeClassifier(self.prune_layer_num, self.min_samples_split,  self.min_samples_leaf)\n",
    "            tree.fit(x_bagged, y_bagged)\n",
    "            \n",
    "            # add to roots\n",
    "            self.roots.append((tree, feature_list))\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        predictions = np.zeros((self.treesNum, len(x)), dtype='str')\n",
    "        # for each tree in roots\n",
    "        for i, (tree, feature_list) in enumerate(self.roots):\n",
    "            predictions[i] = tree.predict(x[:, feature_list])\n",
    "            \n",
    "        # then find mode of predictions\n",
    "        mode, count = np.unique(predictions, return_counts=True, axis=0)\n",
    "        modePredictions = mode[np.argmax(count)]\n",
    "        return modePredictions\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2a37eb88-b693-4aef-b478-c508976f8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = RandomForestClassifier(70, 8, 2, 1, 0.4);\n",
    "test.fit(x_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fb404e4c-4e3f-4f83-b7e7-ef8d199ce4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'A' 'C' 'Q' 'Q' 'C' 'G' 'Q' 'G' 'O' 'G' 'O' 'C' 'O' 'A' 'O' 'C' 'G'\n",
      " 'C' 'A' 'A' 'C' 'A' 'E' 'O' 'G' 'A' 'C' 'E' 'E' 'O' 'A' 'C' 'G' 'E' 'Q'\n",
      " 'O' 'G' 'A' 'O' 'Q' 'Q' 'O' 'G' 'C' 'E' 'G' 'O' 'C' 'E' 'G' 'O' 'G' 'Q'\n",
      " 'O' 'C' 'C' 'A' 'O' 'E' 'E' 'E' 'O' 'Q' 'Q' 'O' 'G' 'E' 'O' 'G' 'A' 'Q'\n",
      " 'Q' 'E' 'C' 'E' 'G' 'E' 'C' 'O' 'O' 'C' 'Q' 'A' 'A' 'C' 'O' 'A' 'A' 'A'\n",
      " 'Q' 'G' 'Q' 'O' 'A' 'A' 'A' 'A' 'O' 'C']\n"
     ]
    }
   ],
   "source": [
    "thirty_predict = test.predict(x_val)\n",
    "print(thirty_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9d226586-3faa-4303-97de-f97504b29bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0]\n",
      " [ 0  0 11  4  1  2]\n",
      " [ 1  2  1  9  0  1]\n",
      " [ 0  1  1  0 17  1]\n",
      " [ 0  1  0  2  3 10]]\n"
     ]
    }
   ],
   "source": [
    "confusion_thirty = confusion_matrix(y_val, thirty_predict)\n",
    "print(confusion_thirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f49b6290-326e-4c59-a0ab-d176b45f6027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(thirty_predict, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bbc54bfe-8a7a-4a8c-90c6-1e69614c1feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C' 'C' 'Q' 'Q' 'G' 'O' 'C' 'C' 'C' 'E' 'A' 'A' 'G' 'A' 'A' 'A' 'G' 'Q'\n",
      " 'E' 'E' 'E' 'E' 'O' 'C' 'Q' 'Q' 'Q' 'C' 'C' 'O' 'E' 'Q' 'G' 'O' 'Q' 'G'\n",
      " 'C' 'O' 'Q' 'A' 'C' 'G' 'O' 'Q' 'A' 'E' 'Q' 'E' 'E' 'Q' 'Q' 'Q' 'O' 'C'\n",
      " 'A' 'G' 'G' 'C' 'G' 'C' 'O' 'E' 'G' 'Q' 'O' 'E' 'G' 'A' 'A' 'O' 'A' 'C'\n",
      " 'Q' 'E' 'G' 'O' 'O' 'A' 'E' 'C' 'A' 'Q' 'C' 'E' 'C' 'A' 'A' 'Q' 'C' 'E'\n",
      " 'A' 'A' 'C' 'Q' 'A' 'Q' 'O' 'Q' 'O' 'Q' 'C' 'G' 'C' 'C' 'O' 'Q' 'A' 'Q'\n",
      " 'Q' 'C' 'E' 'Q' 'C' 'Q' 'Q' 'Q' 'O' 'G' 'Q' 'E' 'O' 'Q' 'E' 'Q' 'Q' 'E'\n",
      " 'O' 'C' 'O' 'A' 'Q' 'Q' 'E' 'G' 'G' 'G' 'E' 'C' 'C' 'O' 'G' 'G' 'Q' 'Q'\n",
      " 'E' 'E' 'A' 'C' 'A' 'G' 'O' 'A' 'C' 'O' 'Q' 'G' 'O' 'O' 'E' 'C' 'C' 'Q'\n",
      " 'Q' 'C' 'C' 'O' 'C' 'A' 'Q' 'A' 'C' 'A' 'C' 'G' 'E' 'Q' 'E' 'C' 'O' 'A'\n",
      " 'C' 'E' 'G' 'O' 'G' 'Q' 'G' 'Q' 'Q' 'C' 'C' 'G' 'G' 'E' 'A' 'G' 'Q' 'O'\n",
      " 'O' 'O']\n"
     ]
    }
   ],
   "source": [
    "test_predict = test.predict(x_test)\n",
    "print(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5f769069-938c-418c-92ed-3457f999de2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.5\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(test_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9d277a12-e725-4baf-baa2-ebb2f99b913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros((10, len(x_val)), dtype='str')\n",
    "\n",
    "for i in range(1,101, 10):\n",
    "    test = RandomForestClassifier(i)\n",
    "    test.fit(x_full, y_full)\n",
    "\n",
    "    predictions[i//10] = (test.predict(x_val))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "046b762f-8f24-4504-9c38-ce3f3cd9241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 88.0\n",
      "1: 82.0\n",
      "2: 85.0\n",
      "3: 86.0\n",
      "4: 84.0\n",
      "5: 82.0\n",
      "6: 91.0\n",
      "7: 85.0\n",
      "8: 92.0\n",
      "9: 89.0\n"
     ]
    }
   ],
   "source": [
    "for i, list in enumerate(predictions):\n",
    "    print(f\"{i}: {accuracy(list, y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "03fe09ff-793e-4d88-a2e7-ca896b18c11f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.05\u001b[39m):\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# create random forest\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     tempForest \u001b[38;5;241m=\u001b[39m RandomForestClassifier(i, j, k, l, m)\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mtempForest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_full\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# save to list\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     config \u001b[38;5;241m=\u001b[39m (i, j, k, l, m, tempForest)\n",
      "Cell \u001b[0;32mIn[124], line 30\u001b[0m, in \u001b[0;36mRandomForestClassifier.fit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# train a tree on this subset\u001b[39;00m\n\u001b[1;32m     29\u001b[0m tree \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprune_layer_num, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split,  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_bagged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bagged\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# add to roots\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroots\u001b[38;5;241m.\u001b[39mappend((tree, feature_list))\n",
      "Cell \u001b[0;32mIn[119], line 127\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minduce_decision_tree(x, y)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_max_depth_from_tree() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers_to_prune\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minduce_decision_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# set a flag so that we know that the classifier has been trained\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_trained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[119], line 105\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.induce_decision_tree\u001b[0;34m(self, x, y, depth)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_left) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_right) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf:\n\u001b[1;32m    104\u001b[0m     parent\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minduce_decision_tree(x_left, y_left, depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m     parent\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minduce_decision_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     label_set, count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[119], line 104\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.induce_decision_tree\u001b[0;34m(self, x, y, depth)\u001b[0m\n\u001b[1;32m    101\u001b[0m (x_left, y_left), (x_right, y_right) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_dataset(x, y, parent)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_left) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_right) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf:\n\u001b[0;32m--> 104\u001b[0m     parent\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minduce_decision_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     parent\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minduce_decision_tree(x_right, y_right, depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[119], line 105\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.induce_decision_tree\u001b[0;34m(self, x, y, depth)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_left) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_right) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf:\n\u001b[1;32m    104\u001b[0m     parent\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minduce_decision_tree(x_left, y_left, depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m     parent\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minduce_decision_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     label_set, count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[119], line 105\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.induce_decision_tree\u001b[0;34m(self, x, y, depth)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_left) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_right) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf:\n\u001b[1;32m    104\u001b[0m     parent\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minduce_decision_tree(x_left, y_left, depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m     parent\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minduce_decision_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     label_set, count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[119], line 104\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.induce_decision_tree\u001b[0;34m(self, x, y, depth)\u001b[0m\n\u001b[1;32m    101\u001b[0m (x_left, y_left), (x_right, y_right) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_dataset(x, y, parent)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_left) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_right) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf:\n\u001b[0;32m--> 104\u001b[0m     parent\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minduce_decision_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     parent\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minduce_decision_tree(x_right, y_right, depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[119], line 104\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.induce_decision_tree\u001b[0;34m(self, x, y, depth)\u001b[0m\n\u001b[1;32m    101\u001b[0m (x_left, y_left), (x_right, y_right) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_dataset(x, y, parent)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_left) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_right) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf:\n\u001b[0;32m--> 104\u001b[0m     parent\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minduce_decision_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     parent\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minduce_decision_tree(x_right, y_right, depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: DecisionTreeClassifier.induce_decision_tree at line 104 (1 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[119], line 104\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.induce_decision_tree\u001b[0;34m(self, x, y, depth)\u001b[0m\n\u001b[1;32m    101\u001b[0m (x_left, y_left), (x_right, y_right) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_dataset(x, y, parent)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_left) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_right) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf:\n\u001b[0;32m--> 104\u001b[0m     parent\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minduce_decision_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     parent\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minduce_decision_tree(x_right, y_right, depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[119], line 95\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.induce_decision_tree\u001b[0;34m(self, x, y, depth)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leaf_node\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     parent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_best_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parent\u001b[38;5;241m.\u001b[39msplit_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf:\n\u001b[1;32m     97\u001b[0m         label_set, count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[119], line -1\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.find_best_node\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# save each configuration\n",
    "    # 6x? array\n",
    "    # 6th index = forest\n",
    "\n",
    "# ranges of configurations\n",
    "    # num of trees\n",
    "    # pruning layers (0-10)\n",
    "    # min split sample size (2-7)\n",
    "    # min leaf sample size (1-6)\n",
    "    # proportions of features (0.3 - 0.9, steps of 0.05)\n",
    "\n",
    "# create array for configs\n",
    "configurations = []\n",
    "\n",
    "# num of trees\n",
    "for i in range(1,101,10):\n",
    "\n",
    "    # pruning range\n",
    "    for j in range(0,10):\n",
    "    \n",
    "        # min split range\n",
    "        for k in range(2,7):\n",
    "    \n",
    "            # min leaf range\n",
    "            for l in range(1,6):\n",
    "    \n",
    "                # feature range\n",
    "                for m in np.arange(0.3, 0.9, 0.05):\n",
    "    \n",
    "                    # create random forest\n",
    "                    tempForest = RandomForestClassifier(i, j, k, l, m)\n",
    "                    tempForest.fit(x_full, y_full)\n",
    "                    \n",
    "                    # save to list\n",
    "                    config = (i, j, k, l, m, tempForest)\n",
    "                    configurations.append(config)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d1519-5084-4813-b933-931e15aca4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
